import streamlit as st
import tensorflow as tf
import pickle
import re
from keras.preprocessing.sequence import pad_sequences
from pyvi import ViTokenizer  # X·ª≠ l√Ω ti·∫øng Vi·ªát
from googletrans import Translator  # Th∆∞ vi·ªán d·ªãch ng√¥n ng·ªØ
import base64


# H√†m chuy·ªÉn h√¨nh ·∫£nh th√†nh base64
def image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode("utf-8")


# T·∫£i m√¥ h√¨nh ƒë√£ l∆∞u
@st.cache_resource
def load_model():
    try:
        model = tf.keras.models.load_model(r'D:\Ung_dung_PTCX\model_cnn_bilstm.keras')
        return model
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i m√¥ h√¨nh: {str(e)}")
        return None


# T·∫£i tokenizer ƒë√£ l∆∞u
@st.cache_resource
def load_tokenizer():
    try:
        with open(r"D:\Ung_dung_PTCX\tokenizer_data.pkl", "rb") as input_file:
            tokenizer = pickle.load(input_file)
        return tokenizer
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i tokenizer: {str(e)}")
        return None


def is_vietnamese(text):
    # H√†m ki·ªÉm tra xem vƒÉn b·∫£n c√≥ ph·∫£i ti·∫øng Vi·ªát kh√¥ng
    vietnamese_chars = "√°√†·∫£√£·∫°√¢·∫•·∫ß·∫©·∫´·∫≠ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑ƒë√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµ"
    for char in vietnamese_chars:
        if char in text.lower():
            return True
    return False

def load_stopwords(filepath):
    # H√†m t·∫£i danh s√°ch stopwords t·ª´ file
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            stopwords = set(f.read().splitlines())
        return stopwords
    except Exception as e:
        st.error(f"L·ªói khi t·∫£i stopwords: {str(e)}")
        return set()

def remove_stopwords(text, stopwords):
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i v√† s·ªë
    text_cleaned = re.sub(r'[^\w\s]', '', text)  # Gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† kho·∫£ng tr·∫Øng
    # T√°ch vƒÉn b·∫£n th√†nh danh s√°ch t·ª´
    words = text_cleaned.split()
    # Lo·∫°i b·ªè stopwords
    filtered_words = [word for word in words if word.lower() not in stopwords]
    # K·∫øt h·ª£p l·∫°i th√†nh vƒÉn b·∫£n
    return " ".join(filtered_words)

# H√†m ti·ªÅn x·ª≠ l√Ω c√¢u ƒë·∫ßu v√†o
def preprocess_raw_input(raw_input, tokenizer):
    # H√†m ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n ƒë·∫ßu v√†o
    input_text_pre = tf.keras.preprocessing.text.text_to_word_sequence(raw_input)
    input_text_pre = " ".join(input_text_pre)

    if is_vietnamese(input_text_pre):
        input_text_pre = ViTokenizer.tokenize(input_text_pre)

    # T·∫£i v√† lo·∫°i b·ªè stopwords
    stopwords = load_stopwords(r"D:\Ung_dung_PTCX\stop_words.txt")
    input_text_pre = remove_stopwords(input_text_pre, stopwords)

    # Tokenize v√† pad sequences
    tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre])
    vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=50)
    return vec_data


# H√†m d·ª± ƒëo√°n
def prediction(raw_input, tokenizer, model):
    input_model = preprocess_raw_input(raw_input, tokenizer)
    result, conf = inference_model(input_model, model)
    return result, conf


# H√†m infer
def inference_model(input_feature, model):
    output = model(input_feature).numpy()[0]
    result = output.argmax()
    conf = float(output.max())
    label_dict = {0: 'ti√™u c·ª±c', 1: 'trung l·∫≠p', 2: 't√≠ch c·ª±c'}
    return label_dict[result], conf


# H√†m d·ªãch ng√¥n ng·ªØ
def translate_text(text, src_lang, dest_lang):
    translator = Translator()  # T·∫°o ƒë·ªëi t∆∞·ª£ng Translator t·ª´ th∆∞ vi·ªán Google Translate
    try:
        translated = translator.translate(text, src=src_lang, dest=dest_lang)  # D·ªãch vƒÉn b·∫£n
        if translated is None or not hasattr(translated, 'text'):  # Ki·ªÉm tra k·∫øt qu·∫£ d·ªãch
            raise ValueError("API Google Translate kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£.")  # N·∫øu kh√¥ng c√≥ k·∫øt qu·∫£
        return translated.text  # Tr·∫£ v·ªÅ vƒÉn b·∫£n d·ªãch
    except Exception as e:
        return f"L·ªói khi d·ªãch: {str(e)}"  # B·∫Øt l·ªói n·∫øu c√≥ b·∫•t k·ª≥ v·∫•n ƒë·ªÅ n√†o

# Trang ch√≠nh
def home_page():
    # CSS ƒë·ªÉ t√πy ch·ªânh giao di·ªán
    st.markdown("""
        <style>
        .main-container {
            background-color: #f9f9f9;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1);
        }
        .header {
            text-align: center;
            font-size: 36px;
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 10px;
        }
        .description {
            text-align: center;
            font-size: 18px;
            color: #34495e;
            margin-bottom: 30px;
        }
        .functions {
            margin-top: 10px;
            font-size: 18px;
            color: #555555;
        }
        .functions ul {
            list-style-type: none;
            padding-left: 0;
        }
        .functions li {
            margin: 15px 0;
            display: flex;
            align-items: center;
        }
        .functions li span.icon {
            font-size: 24px;
            margin-right: 10px;
        }
        img {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 60%;
            border-radius: 10px;
            box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1);
        }
        </style>
        """, unsafe_allow_html=True)

    # Hi·ªÉn th·ªã giao di·ªán ch√≠nh
    image_base64 = image_to_base64(r"D:\Ung_dung_PTCX\decoration.png")  # S·ª≠ d·ª•ng h√¨nh ·∫£nh ƒë√£ c·∫≠p nh·∫≠t
    st.markdown(f"""
    <div class="main-container">
        <div class="header">·ª®ng d·ª•ng ph√¢n t√≠ch c·∫£m x√∫c ƒëa ng√¥n ng·ªØ</div>
        <div class="description">
            Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ vƒÉn b·∫£n m·ªôt c√°ch nhanh ch√≥ng v√† hi·ªáu qu·∫£.
        </div>
        <img src="data:image/png;base64,{image_base64}" alt="sentiment image">
        <div class="functions">
            <h4>Ch·ª©c nƒÉng ch√≠nh:</h4>
            <ul>
                <li><span class="icon">üí≠</span><b>Ph√¢n t√≠ch c·∫£m x√∫c:</b> Ti√™u c·ª±c, Trung l·∫≠p, T√≠ch c·ª±c.</li>
                <li><span class="icon">üåê</span><b>D·ªãch ng√¥n ng·ªØ:</b> T·ª± ƒë·ªông d·ªãch gi·ªØa Ti·∫øng Vi·ªát v√† Ti·∫øng Anh.</li>
                <li><span class="icon">üìä</span><b>T√¨m hi·ªÉu d·ªØ li·ªáu:</b> Th√¥ng tin chi ti·∫øt v·ªÅ t·∫≠p d·ªØ li·ªáu.</li>
            </ul>
        </div>
    </div>
    """, unsafe_allow_html=True)


# Trang gi·ªõi thi·ªáu d·ªØ li·ªáu
def data_intro_page():
    # CSS t√πy ch·ªânh
    st.markdown("""
        <style>
        .header-container {
            text-align: center;
            margin-bottom: 30px;
        }
        .header-container h1 {
            font-size: 36px;
            font-weight: bold;
            color: #2c3e50;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            margin-bottom: 5px;
        }
        .header-container p {
            font-size: 18px;
            color: #7f8c8d;
        }
        .data-section {
            margin-top: 20px;
            margin-bottom: 30px;
        }
        .data-section h4 {
            font-size: 24px;
            color: #34495e;
            border-left: 4px solid #3498db;
            padding-left: 10px;
        }
        .data-section ul {
            margin-top: 10px;
            list-style: none;
            padding-left: 0;
        }
        .data-section ul li {
            font-size: 18px;
            color: #2d3436;
            margin-bottom: 10px;
        }
        .data-section ul li span {
            font-weight: bold;
            color: #2980b9;
        }
        .data-section ul li span.negative {
            color: #e74c3c;
        }
        .data-section ul li span.neutral {
            color: #f39c12;
        }
        .data-section ul li span.positive {
            color: #27ae60;
        }
        </style>
    """, unsafe_allow_html=True)

    # Giao di·ªán ch√≠nh
    st.markdown("""
    <div class="header-container">
        <h1>üìä Gi·ªõi thi·ªáu D·ªØ li·ªáu</h1>
        <p>T√¨m hi·ªÉu t·ªïng quan v·ªÅ c√°c b·ªô d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c.</p>
    </div>
    """, unsafe_allow_html=True)

    # D·ªØ li·ªáu ti·∫øng Vi·ªát
    st.markdown("""
    <div class="data-section">
        <h4>üìò D·ªØ li·ªáu Ti·∫øng Vi·ªát</h4>
        <ul>
            <li><span>üìç Ngu·ªìn g·ªëc:</span> B·ªô d·ªØ li·ªáu UIT-VSFC (Vietnamese Students Feedback Corpus).</li>
            <li><span>üìä S·ªë l∆∞·ª£ng:</span> 11,426 ph·∫£n h·ªìi.</li>
            <li><span>üìã M√¥ t·∫£:</span> G·ªìm c√°c c√¢u ph·∫£n h·ªìi t·ª´ sinh vi√™n, thu·ªôc c√°c ch·ªß ƒë·ªÅ v·ªÅ ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o, c∆° s·ªü v·∫≠t ch·∫•t, gi·∫£ng vi√™n v√† kh√°c.</li>
            <li><span>üìå Ph√¢n lo·∫°i c·∫£m x√∫c:</span> <span class="negative">‚ùå Ti√™u c·ª±c</span>, <span class="neutral">‚ûñ Trung l·∫≠p</span>, <span class="positive">‚úÖ T√≠ch c·ª±c</span>.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    # D·ªØ li·ªáu ti·∫øng Anh
    st.markdown("""
    <div class="data-section">
        <h4>üìô D·ªØ li·ªáu Ti·∫øng Anh</h4>
        <ul>
            <li><span>üìç Ngu·ªìn g·ªëc:</span> Thu th·∫≠p t·ª´ ph·∫£n h·ªìi kh√°ch h√†ng trong lƒ©nh v·ª±c nh√† h√†ng.</li>
            <li><span>üìä S·ªë l∆∞·ª£ng:</span> 3,693 c√¢u ph·∫£n h·ªìi.</li>
            <li><span>üìã M√¥ t·∫£:</span> G·ªìm c√°c nh·∫≠n x√©t ƒë√°nh gi√° v·ªÅ ch·∫•t l∆∞·ª£ng ph·ª•c v·ª•, m√≥n ƒÉn v√† kh√¥ng gian nh√† h√†ng.</li>
            <li><span>üìå Ph√¢n lo·∫°i c·∫£m x√∫c:</span> <span class="negative">‚ùå Ti√™u c·ª±c</span>, <span class="neutral">‚ûñ Trung l·∫≠p</span>, <span class="positive">‚úÖ T√≠ch c·ª±c</span>.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# Trang d·ª± ƒëo√°n
def prediction_page(model, tokenizer):
    st.title("üåü D·ª± ƒëo√°n c·∫£m x√∫c üåü")
    st.markdown("### Nh·∫≠p vƒÉn b·∫£n v√† ƒë·ªÉ AI gi√∫p b·∫°n ph√¢n t√≠ch c·∫£m x√∫c!")

    # Th√™m CSS ƒë·ªÉ t√πy ch·ªânh n√∫t
    st.markdown("""
    <style>
        .stButton>button {
            background-color: #4CAF50; /* M√†u n·ªÅn n√∫t */
            color: white; /* M√†u ch·ªØ */
            padding: 10px 20px; /* ƒê·ªám */
            font-size: 16px; /* K√≠ch th∆∞·ªõc ch·ªØ */
            border: none; /* X√≥a vi·ªÅn */
            border-radius: 8px; /* Bo g√≥c */
            cursor: pointer;
            transition-duration: 0.4s; /* Hi·ªáu ·ª©ng hover */
        }
        .stButton>button:hover {
            background-color: #45a049; /* M√†u khi hover */
        }
    </style>
    """, unsafe_allow_html=True)

    # Khu v·ª±c nh·∫≠p vƒÉn b·∫£n
    text = st.text_area("‚úçÔ∏è VƒÉn b·∫£n", "", height=150, placeholder="V√≠ d·ª•: T√¥i c·∫£m th·∫•y r·∫•t vui h√¥m nay!")

    if text.strip():
        source_lang, dest_lang = ('vi', 'en') if is_vietnamese(text) else ('en', 'vi')

        # T·∫°o b·ªë c·ª•c h√†ng ngang cho c√°c n√∫t
        col1, col2 = st.columns(2)
        with col1:
            if st.button("üåê D·ªãch sang ng√¥n ng·ªØ kh√°c"):
                try:
                    translated_text = translate_text(text, src_lang=source_lang, dest_lang=dest_lang)
                    st.markdown(f"**D·ªãch ({'üáªüá≥ Ti·∫øng Vi·ªát' if source_lang == 'en' else 'üá∫üá∏ Ti·∫øng Anh'}):**")
                    st.info(translated_text)
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi d·ªãch: {str(e)}")

        with col2:
            if st.button("üìä Ph√¢n t√≠ch c·∫£m x√∫c"):
                try:
                    result, conf = prediction(text, tokenizer, model)

                    # Hi·ªÉn th·ªã c·∫£m x√∫c b·∫±ng hi·ªáu ·ª©ng
                    if result == "ti√™u c·ª±c":
                        st.snow()
                        st.image(r"D:\Ung_dung_PTCX\negative.png", caption="C·∫£m x√∫c Ti√™u c·ª±c")
                    elif result == "trung l·∫≠p":
                        st.image(r"D:\Ung_dung_PTCX\neutral.png", caption="C·∫£m x√∫c trung l·∫≠p")
                    else:
                        st.balloons()
                        st.image(r"D:\Ung_dung_PTCX\positive.png", caption="C·∫£m x√∫c T√≠ch c·ª±c")

                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ v√† ƒë·ªô ch√≠nh x√°c
                    st.success(f"**D·ª± ƒëo√°n c·∫£m x√∫c:** {result.upper()}")
                    st.info(f"üéØ **ƒê·ªô ch√≠nh x√°c:** {conf:.2f}%")
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch c·∫£m x√∫c: {str(e)}")
    else:
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c!")


# Main function
def main():
    st.sidebar.title("B·∫£ng Dashboard")
    app_mode = st.sidebar.radio("Ch·ªçn Trang", ["Trang ch·ªß", "Gi·ªõi thi·ªáu d·ªØ li·ªáu", "D·ª± ƒëo√°n"])

    if app_mode == "Trang ch·ªß":
        home_page()
    elif app_mode == "Gi·ªõi thi·ªáu d·ªØ li·ªáu":
        data_intro_page()
    elif app_mode == "D·ª± ƒëo√°n":
        model = load_model()
        tokenizer = load_tokenizer()
        if not model or not tokenizer:
            st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh ho·∫∑c tokenizer. Vui l√≤ng ki·ªÉm tra l·∫°i.")
        else:
            prediction_page(model, tokenizer)


if __name__ == "__main__":
    main()
